{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET SOBRE EL CANCER DE SCIKIT-LEARN\n",
    "\n",
    "El objetivo es predecir en función de los datos del tumor de un paciente si dicho tumor es Maligno (1) o Benigno (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius           mean perimeter          0.997855\n",
      "                      mean area               0.987357\n",
      "                      worst radius            0.969539\n",
      "                      worst perimeter         0.965137\n",
      "                      worst area              0.941082\n",
      "mean texture          worst texture           0.912045\n",
      "mean perimeter        mean radius             0.997855\n",
      "                      mean area               0.986507\n",
      "                      worst radius            0.969476\n",
      "                      worst perimeter         0.970387\n",
      "                      worst area              0.941550\n",
      "mean area             mean radius             0.987357\n",
      "                      mean perimeter          0.986507\n",
      "                      worst radius            0.962746\n",
      "                      worst perimeter         0.959120\n",
      "                      worst area              0.959213\n",
      "mean concavity        mean concave points     0.921391\n",
      "mean concave points   mean concavity          0.921391\n",
      "                      worst concave points    0.910155\n",
      "radius error          perimeter error         0.972794\n",
      "                      area error              0.951830\n",
      "perimeter error       radius error            0.972794\n",
      "                      area error              0.937655\n",
      "area error            radius error            0.951830\n",
      "                      perimeter error         0.937655\n",
      "worst radius          mean radius             0.969539\n",
      "                      mean perimeter          0.969476\n",
      "                      mean area               0.962746\n",
      "                      worst perimeter         0.993708\n",
      "                      worst area              0.984015\n",
      "worst texture         mean texture            0.912045\n",
      "worst perimeter       mean radius             0.965137\n",
      "                      mean perimeter          0.970387\n",
      "                      mean area               0.959120\n",
      "                      worst radius            0.993708\n",
      "                      worst area              0.977578\n",
      "worst area            mean radius             0.941082\n",
      "                      mean perimeter          0.941550\n",
      "                      mean area               0.959213\n",
      "                      worst radius            0.984015\n",
      "                      worst perimeter         0.977578\n",
      "worst concave points  mean concave points     0.910155\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cargar dataset\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df[\"target\"] = data.target  # 1 = Maligno, 0 = Benigno\n",
    "\n",
    "# Analizamos el contenido del DataFrame\n",
    "\"\"\"print(df.info())\n",
    "print(df.describe())\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {len(df[col].unique())}\")\"\"\"\n",
    "\n",
    "# Matriz de correlación\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Filtrar valores mayores a 0.9 (excluyendo la diagonal)\n",
    "filtered = corr_matrix.where((corr_matrix > 0.9) & (corr_matrix < 1)).stack()\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados con Sobremuestreo Aleatorio:\n",
      "Accuracy: 98.25%\n",
      "Precision: 98.59%\n",
      "Recall: 98.59%\n",
      "F1-Score: 98.59%\n",
      "AUC-ROC: 99.80%\n",
      "\n",
      "Resultados con SMOTE:\n",
      "Accuracy: 98.25%\n",
      "Precision: 98.59%\n",
      "Recall: 98.59%\n",
      "F1-Score: 98.59%\n",
      "AUC-ROC: 99.84%\n",
      "\n",
      "Resultados con Submuestreo Aleatorio:\n",
      "Accuracy: 97.37%\n",
      "Precision: 98.57%\n",
      "Recall: 97.18%\n",
      "F1-Score: 97.87%\n",
      "AUC-ROC: 99.84%\n",
      "\n",
      "Resultados con NearMiss:\n",
      "Accuracy: 96.49%\n",
      "Precision: 97.18%\n",
      "Recall: 97.18%\n",
      "F1-Score: 97.18%\n",
      "AUC-ROC: 99.80%\n",
      "\n",
      "El mejor método de balanceo es: SMOTE con F1-Score: 98.59% y AUC-ROC: 99.84%\n",
      "\n",
      "Resultados con ajuste manual de hiperparámetros:\n",
      "Accuracy: 98.25%\n",
      "Precision: 98.59%\n",
      "Recall: 98.59%\n",
      "F1-Score: 98.59%\n",
      "AUC-ROC: 99.84%\n",
      "\n",
      "Resultados con ajuste automático de hiperparámetros:\n",
      "Mejores parámetros: {'C': 0.1, 'solver': 'lbfgs'}\n",
      "Mejor Accuracy en validación cruzada: 98.08%\n",
      "Accuracy: 98.25%\n",
      "Precision: 98.59%\n",
      "Recall: 98.59%\n",
      "F1-Score: 98.59%\n",
      "AUC-ROC: 99.84%\n",
      "      Real Predicción\n",
      "0  Maligno    Maligno\n",
      "1  Benigno    Benigno\n",
      "2  Benigno    Benigno\n",
      "3  Maligno    Maligno\n",
      "4  Maligno    Maligno\n",
      "5  Benigno    Benigno\n",
      "6  Benigno    Benigno\n",
      "7  Benigno    Benigno\n",
      "8  Maligno    Maligno\n",
      "9  Maligno    Maligno\n"
     ]
    }
   ],
   "source": [
    "# Elejimos las variables predictoras y objetivo\n",
    "X = df.drop([\"target\"], axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Preprocesamos las columnas numéricas\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# División de datos entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --------------------\n",
    "# MÉTODOS DE BALANCEO DE CLASES\n",
    "# --------------------\n",
    "# 1. Sobremuestreo aleatorio\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# 2. SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 3. Submuestreo aleatorio\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# 4. NearMiss (submuestreo basado en distancia)\n",
    "nearmiss = NearMiss()\n",
    "X_train_nm, y_train_nm = nearmiss.fit_resample(X_train, y_train)\n",
    "\n",
    "# --------------------\n",
    "# EVALUACIÓN DE MÉTODOS DE BALANCEO\n",
    "# --------------------\n",
    "resultados_balanceo = {}\n",
    "\n",
    "def evaluar_balanceo(X_train_resampled, y_train_resampled, metodo):\n",
    "    # Creación del modelo de RL\n",
    "    model = LogisticRegression(C=0.1, solver='liblinear', max_iter=500)\n",
    "    # Entreno el modelo con los datos de cada modelo\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    # Realizo predicciones con el modelo\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calculo la precisión del modelo sacando las métricas\n",
    "    f1 = f1_score(y_test, y_pred) * 100\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1]) * 100\n",
    "    resultados_balanceo[metodo] = (f1, auc)\n",
    "    # Imprimimos los resultados\n",
    "    print(f\"\\nResultados con {metodo}:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"F1-Score: {f1:.2f}%\")\n",
    "    print(f\"AUC-ROC: {auc:.2f}%\")\n",
    "\n",
    "evaluar_balanceo(X_train_ros, y_train_ros, \"Sobremuestreo Aleatorio\")\n",
    "evaluar_balanceo(X_train_smote, y_train_smote, \"SMOTE\")\n",
    "evaluar_balanceo(X_train_rus, y_train_rus, \"Submuestreo Aleatorio\")\n",
    "evaluar_balanceo(X_train_nm, y_train_nm, \"NearMiss\")\n",
    "\n",
    "# Seleccionar el mejor método de balanceo\n",
    "mejor_metodo = max(resultados_balanceo, key=lambda k: resultados_balanceo[k])\n",
    "print(f\"\\nEl mejor método de balanceo es: {mejor_metodo} con F1-Score: {resultados_balanceo[mejor_metodo][0]:.2f}% y AUC-ROC: {resultados_balanceo[mejor_metodo][1]:.2f}%\")\n",
    "\n",
    "# Obtener los datos balanceados del mejor método encontrado\n",
    "if mejor_metodo == \"Sobremuestreo Aleatorio\":\n",
    "    X_train_resampled, y_train_resampled = X_train_ros, y_train_ros\n",
    "elif mejor_metodo == \"SMOTE\":\n",
    "    X_train_resampled, y_train_resampled = X_train_smote, y_train_smote\n",
    "elif mejor_metodo == \"Submuestreo Aleatorio\":\n",
    "    X_train_resampled, y_train_resampled = X_train_rus, y_train_rus\n",
    "elif mejor_metodo == \"NearMiss\":\n",
    "    X_train_resampled, y_train_resampled = X_train_nm, y_train_nm\n",
    "\n",
    "# --------------------\n",
    "# MÉTODO 1: Ajuste manual de hiperparámetros\n",
    "# --------------------\n",
    "manual_model = LogisticRegression(C=0.1, solver='liblinear', max_iter=500)  # Ejemplo de hiperparámetros ajustados manualmente\n",
    "manual_model.fit(X_train_resampled, y_train_resampled)  # Entrenar modelo\n",
    "\n",
    "# Predicciones\n",
    "y_pred_manual = manual_model.predict(X_test)\n",
    "\n",
    "# Evaluación del modelo ajustado manualmente\n",
    "print(\"\\nResultados con ajuste manual de hiperparámetros:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, manual_model.predict_proba(X_test)[:,1]) * 100:.2f}%\")\n",
    "\n",
    "# --------------------\n",
    "# MÉTODO 2: Ajuste automático con GridSearchCV\n",
    "# --------------------\n",
    "parametros = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],  # Diferentes valores de regularización\n",
    "    \"solver\": [\"liblinear\", \"lbfgs\"]  # Diferentes algoritmos de optimización\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=500), parametros, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)  # Entrenar búsqueda de hiperparámetros\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicciones del mejor modelo\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluación del mejor modelo\n",
    "print(\"\\nResultados con ajuste automático de hiperparámetros:\")\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor Accuracy en validación cruzada: {grid_search.best_score_ * 100:.2f}%\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1]) * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# ENTRENAMIENTO FINAL Y EVALUACIÓN\n",
    "# --------------------\n",
    "\n",
    "# Entrenar el mejor modelo con los datos balanceados\n",
    "best_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Realizar predicciones finales con el mejor modelo y el mejor balanceo\n",
    "y_pred_final = best_model.predict(X_test)\n",
    "\n",
    "# Crear DataFrame de resultados\n",
    "resultados = pd.DataFrame({\n",
    "    \"Real\": y_test.values,\n",
    "    \"Predicción\": y_pred_final\n",
    "})\n",
    "\n",
    "# Mapear valores 0 y 1 a etiquetas comprensibles\n",
    "resultados[\"Real\"] = resultados[\"Real\"].map({0: \"Benigno\", 1: \"Maligno\"})\n",
    "resultados[\"Predicción\"] = resultados[\"Predicción\"].map({0: \"Benigno\", 1: \"Maligno\"})\n",
    "\n",
    "# Mostrar las primeras filas de la tabla\n",
    "print(resultados.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "Obtenemos una precisión del 99.84%, por lo tanto nuestro modelo predice con un margen de error practicamente nulo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba del modelo\n",
    "\n",
    "Pasamos datos nuevos al modelo para ver si predice correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 19,  20,  21,  37,  46,  48,  49,  50,  51,  52,\n",
      "       ...\n",
      "       553, 554, 555, 556, 557, 558, 559, 560, 561, 568],\n",
      "      dtype='int64', length=357)\n",
      "mean radius                 13.030000\n",
      "mean texture                18.420000\n",
      "mean perimeter              82.610000\n",
      "mean area                  523.800000\n",
      "mean smoothness              0.089830\n",
      "mean compactness             0.037660\n",
      "mean concavity               0.025620\n",
      "mean concave points          0.029230\n",
      "mean symmetry                0.146700\n",
      "mean fractal dimension       0.058630\n",
      "radius error                 0.183900\n",
      "texture error                2.342000\n",
      "perimeter error              1.170000\n",
      "area error                  14.160000\n",
      "smoothness error             0.004352\n",
      "compactness error            0.004899\n",
      "concavity error              0.013430\n",
      "concave points error         0.011640\n",
      "symmetry error               0.026710\n",
      "fractal dimension error      0.001777\n",
      "worst radius                13.300000\n",
      "worst texture               22.810000\n",
      "worst perimeter             84.460000\n",
      "worst area                 545.900000\n",
      "worst smoothness             0.097010\n",
      "worst compactness            0.046190\n",
      "worst concavity              0.048330\n",
      "worst concave points         0.050130\n",
      "worst symmetry               0.198700\n",
      "worst fractal dimension      0.061690\n",
      "target                       1.000000\n",
      "Name: 37, dtype: float64\n",
      "\n",
      "Ingrese los valores para realizar una predicción:\n",
      "\n",
      "Predicción: Maligno (99.72% de confianza)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SergioSF\\Desktop\\Programacion de Modelos de IA\\Ejercicios y apuntes\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Buscamos un registro de un paciente con cancer para pasar los mismos datos y probar que el modelo predice correctamente\n",
    "print(df[df[\"target\"] == 1].index) # Seleccionamos la 37\n",
    "print(df.loc[37])\n",
    "\n",
    "# Mapeo de características a nombres en castellano (opcional)\n",
    "nombres_caracteristicas = {\n",
    "    'mean radius': 'Radio promedio',\n",
    "    'mean texture': 'Textura promedio',\n",
    "    'mean perimeter': 'Perímetro promedio',\n",
    "    'mean area': 'Área promedio',\n",
    "    'mean smoothness': 'Suavidad promedio',\n",
    "    'mean compactness': 'Compacidad promedio',\n",
    "    'mean concavity': 'Concavidad promedio',\n",
    "    'mean concave points': 'Puntos cóncavos promedio',\n",
    "    'mean symmetry': 'Simetría promedio',\n",
    "    'mean fractal dimension': 'Dimensión fractal promedio',\n",
    "    'radius error': 'Error de radio',\n",
    "    'texture error': 'Error de textura',\n",
    "    'perimeter error': 'Error de perímetro',\n",
    "    'area error': 'Error de área',\n",
    "    'smoothness error': 'Error de suavidad',\n",
    "    'compactness error': 'Error de compacidad',\n",
    "    'concavity error': 'Error de concavidad',\n",
    "    'concave points error': 'Error de puntos cóncavos',\n",
    "    'symmetry error': 'Error de simetría',\n",
    "    'fractal dimension error': 'Error de dimensión fractal',\n",
    "    'worst radius': 'Radio máximo',\n",
    "    'worst texture': 'Textura máxima',\n",
    "    'worst perimeter': 'Perímetro máximo',\n",
    "    'worst area': 'Área máxima',\n",
    "    'worst smoothness': 'Suavidad máxima',\n",
    "    'worst compactness': 'Compacidad máxima',\n",
    "    'worst concavity': 'Concavidad máxima',\n",
    "    'worst concave points': 'Puntos cóncavos máximos',\n",
    "    'worst symmetry': 'Simetría máxima',\n",
    "    'worst fractal dimension': 'Dimensión fractal máxima'\n",
    "}\n",
    "\n",
    "# Creamos la función para ejecutar el modelo con nuevos datos\n",
    "def solicitar_datos_y_predecir(modelo, feature_names, scaler):\n",
    "    print(\"\\nIngrese los valores para realizar una predicción:\")\n",
    "    valores = []\n",
    "    \n",
    "    for feature in feature_names:\n",
    "        nombre_caracteristica = nombres_caracteristicas.get(feature, feature)  \n",
    "        while True:\n",
    "            try:\n",
    "                valor = float(input(f\"{nombre_caracteristica}: \"))\n",
    "                valores.append(valor)\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"Entrada inválida. Ingrese un número válido.\")\n",
    "    \n",
    "    # Convertir la entrada en un array de numpy y escalarlo con el scaler ya entrenado\n",
    "    datos_nuevos = np.array(valores).reshape(1, -1)\n",
    "    datos_nuevos_escalados = scaler.transform(datos_nuevos)\n",
    "    \n",
    "    # Realizar predicción\n",
    "    prediccion = modelo.predict(datos_nuevos_escalados)[0]\n",
    "    probabilidad = modelo.predict_proba(datos_nuevos_escalados)[0][prediccion] * 100\n",
    "    \n",
    "    # Mostrar resultado\n",
    "    resultado = \"Maligno\" if prediccion == 1 else \"Benigno\"\n",
    "    print(f\"\\nPredicción: {resultado} ({probabilidad:.2f}% de confianza)\\n\")\n",
    "\n",
    "# Llamar a la función con el scaler ya ajustado\n",
    "solicitar_datos_y_predecir(best_model, data.feature_names, scaler)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
