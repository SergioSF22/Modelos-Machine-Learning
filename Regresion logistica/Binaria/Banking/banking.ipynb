{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET BANKING\n",
    "\n",
    "En función de las diferentes características de un solicitante de un préstamo, decicidir si se le concede dicho préstamo (1) o no (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: [44 53 28 39 55 30 37 36 27 34 41 33 26 52 35 40 32 49 38 47 46 29 54 42\n",
      " 72 48 43 56 31 24 68 59 50 45 25 57 63 58 60 64 51 23 20 74 80 61 62 75\n",
      " 21 82 77 70 76 73 66 22 71 19 79 88 65 67 81 18 84 69 98 85 83 78 92 86\n",
      " 94 17 91 89 87 95]\n",
      "job: ['blue-collar' 'technician' 'management' 'services' 'retired' 'admin.'\n",
      " 'housemaid' 'unemployed' 'entrepreneur' 'self-employed' 'unknown'\n",
      " 'student']\n",
      "marital: ['married' 'single' 'divorced' 'unknown']\n",
      "education: ['basic.4y' 'unknown' 'university.degree' 'high.school' 'basic.9y'\n",
      " 'professional.course' 'basic.6y' 'illiterate']\n",
      "default: ['unknown' 'no' 'yes']\n",
      "housing: ['yes' 'no' 'unknown']\n",
      "loan: ['no' 'yes' 'unknown']\n",
      "contact: ['cellular' 'telephone']\n",
      "month: ['aug' 'nov' 'jun' 'apr' 'jul' 'may' 'oct' 'mar' 'sep' 'dec']\n",
      "day_of_week: ['thu' 'fri' 'tue' 'mon' 'wed']\n",
      "duration: [ 210  138  339 ... 2260 1662 1490]\n",
      "campaign: [ 1  3  2  8  5  4 25 11 12 18  6 17  7 20 16 14 10  9 19 29 13 40 15 34\n",
      " 22 24 41 21 23 39 28 27 31 35 26 30 32 43 33 42 56 37]\n",
      "pdays: [999   6   3   2   4  16   0   5  11  14  13   9  15  17  12  26   7  19\n",
      "  10   1  18   8  20  21  22  25  27]\n",
      "previous: [0 2 1 3 4 5 7 6]\n",
      "poutcome: ['nonexistent' 'success' 'failure']\n",
      "emp_var_rate: [ 1.4 -0.1 -1.7 -1.8 -2.9  1.1 -3.4 -1.1 -3.  -0.2]\n",
      "cons_price_idx: [93.444 93.2   94.055 93.075 92.201 93.918 92.893 92.963 93.994 94.465\n",
      " 93.798 92.431 92.649 92.843 92.469 93.749 93.876 94.027 94.199 94.601\n",
      " 92.713 94.767 93.369 94.215 92.379 92.756]\n",
      "cons_conf_idx: [-36.1 -42.  -39.8 -47.1 -31.4 -42.7 -46.2 -40.8 -36.4 -41.8 -40.4 -26.9\n",
      " -30.1 -50.  -33.6 -34.6 -40.  -38.3 -37.5 -49.5 -33.  -50.8 -34.8 -40.3\n",
      " -29.8 -45.9]\n",
      "euribor3m: [4.963 4.021 0.729 1.405 0.869 4.961 1.327 1.313 1.266 1.41  4.864 4.964\n",
      " 4.965 1.291 4.96  4.962 1.365 4.86  4.967 4.968 1.344 0.754 1.299 1.268\n",
      " 1.334 4.857 0.715 4.966 4.076 1.354 4.959 4.958 4.859 1.27  4.856 1.811\n",
      " 1.029 1.259 4.866 0.883 4.858 1.56  0.74  4.245 4.12  0.659 1.415 0.73\n",
      " 1.072 4.153 0.716 0.682 0.905 1.281 4.865 4.957 0.914 0.849 0.876 0.644\n",
      " 4.855 1.392 1.25  0.873 0.881 0.942 0.9   0.692 1.244 1.264 4.191 0.882\n",
      " 1.035 0.742 0.879 1.032 0.719 5.    0.724 4.97  0.646 1.26  1.479 0.87\n",
      " 1.423 1.498 0.803 0.714 1.406 0.702 0.827 0.71  4.955 0.653 4.947 0.835\n",
      " 1.531 0.735 0.743 1.262 0.944 1.028 0.663 0.731 0.699 1.435 1.538 0.846\n",
      " 0.884 1.453 1.445 0.635 0.885 0.854 0.748 0.643 0.728 0.893 0.861 0.706\n",
      " 1.025 4.912 0.668 0.899 1.085 0.654 0.88  0.781 1.059 0.636 0.965 0.72\n",
      " 0.896 1.602 0.741 1.614 0.84  1.483 0.773 0.701 0.721 0.697 0.985 0.829\n",
      " 0.761 0.903 1.466 0.809 1.049 0.959 0.717 1.703 1.04  0.898 1.05  0.739\n",
      " 1.    0.645 1.007 0.655 1.252 0.683 1.044 0.651 0.767 0.797 0.822 0.904\n",
      " 0.642 0.752 0.722 1.224 0.977 0.707 1.548 3.563 1.016 1.556 1.663 0.744\n",
      " 1.031 0.851 0.64  0.708 0.878 1.043 0.886 0.639 0.793 0.788 0.652 4.794\n",
      " 0.819 1.206 0.859 1.687 0.737 4.956 1.799 1.51  0.77  0.753 0.877 0.908\n",
      " 1.041 0.677 0.723 0.937 4.918 0.987 1.046 4.936 0.704 0.712 1.384 0.711\n",
      " 0.821 1.757 0.695 0.843 1.52  0.838 0.825 4.7   1.03  1.048 0.733 4.474\n",
      " 0.768 0.982 0.65  0.684 1.037 0.634 1.235 0.921 0.718 0.685 1.65  1.64\n",
      " 1.286 0.732 5.045 0.649 1.4   4.663 0.778 0.672 1.629 1.372 1.726 0.75\n",
      " 0.688 0.709 0.713 1.215 0.889 4.827 0.834 0.933 3.743 0.727 0.755 1.584\n",
      " 4.406 0.89  0.81  0.972 0.782 0.638 1.039 0.79  0.802 3.853 1.099 0.7\n",
      " 0.762 4.76  0.953 0.766 0.637 1.778 0.771 3.053 3.329 0.969 0.813 0.894\n",
      " 4.733 0.895 3.879 4.286 4.592 3.901 0.979 0.891 1.047 0.927 1.018 1.008\n",
      " 1.045 0.749 0.888 4.921 0.993 0.956 4.223 0.69  0.996 3.669 1.574 3.488\n",
      " 3.428 4.343 3.816 3.282]\n",
      "nr_employed: [5228.1 5195.8 4991.6 5099.1 5076.2 5191.  5017.5 5008.7 4963.6 5023.5\n",
      " 5176.3]\n",
      "y: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el CSV en un dataframe\n",
    "df = pd.read_csv(\"banking.csv\")\n",
    "\n",
    "# Imprimimos información del csv para ver con que datos trabajamos\n",
    "# print(df.info())\n",
    "# print(df.describe())\n",
    "\n",
    "# Imprimimos los valores únicos de las columnas para saber que preprocesamiento aplicar sobre cada uno (OnehotEncoder, StandarScaler...)\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].unique()}\")\n",
    "\n",
    "# Resumir la columna educación\n",
    "df[\"education\"] = np.where((df[\"education\"] == 'basic.4y') | (df[\"education\"] == 'basic.6y') | (df[\"education\"] == 'basic.9y'), \n",
    "                           'Basic', \n",
    "                           df[\"education\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante la información obtenida al analizar el contenido y tipo de las columnas llegamos a la conclusión de que las variables categóricas no poseen nignuna un orden de prioridad o peso, por lo que emplearemos el OneHot Encoder para la encodificación de todas ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados con Sobremuestreo Aleatorio:\n",
      "Accuracy: 85.64%\n",
      "Precision: 43.76%\n",
      "Recall: 89.29%\n",
      "F1-Score: 58.74%\n",
      "AUC-ROC: 93.52%\n",
      "\n",
      "Resultados con SMOTE:\n",
      "Accuracy: 86.17%\n",
      "Precision: 44.76%\n",
      "Recall: 88.76%\n",
      "F1-Score: 59.51%\n",
      "AUC-ROC: 93.41%\n",
      "\n",
      "Resultados con Submuestreo Aleatorio:\n",
      "Accuracy: 85.43%\n",
      "Precision: 43.40%\n",
      "Recall: 89.61%\n",
      "F1-Score: 58.48%\n",
      "AUC-ROC: 93.39%\n",
      "\n",
      "Resultados con NearMiss:\n",
      "Accuracy: 74.36%\n",
      "Precision: 29.32%\n",
      "Recall: 87.91%\n",
      "F1-Score: 43.98%\n",
      "AUC-ROC: 88.33%\n",
      "\n",
      "El mejor método de balanceo es: SMOTE con F1-Score: 59.51% y AUC-ROC: 93.41%\n",
      "\n",
      "Resultados con ajuste manual de hiperparámetros:\n",
      "Accuracy: 86.17%\n",
      "Precision: 44.76%\n",
      "Recall: 88.76%\n",
      "F1-Score: 59.51%\n",
      "AUC-ROC: 93.41%\n",
      "\n",
      "Resultados con ajuste automático de hiperparámetros:\n",
      "Mejores parámetros: {'C': 10, 'solver': 'lbfgs'}\n",
      "Mejor Accuracy en validación cruzada: 88.52%\n",
      "Accuracy: 86.17%\n",
      "Precision: 44.74%\n",
      "Recall: 88.44%\n",
      "F1-Score: 59.42%\n",
      "AUC-ROC: 93.39%\n",
      "   Real  Predicción\n",
      "0     0           0\n",
      "1     1           0\n",
      "2     1           1\n",
      "3     0           0\n",
      "4     0           0\n",
      "5     1           0\n",
      "6     0           0\n",
      "7     0           0\n",
      "8     0           0\n",
      "9     0           0\n"
     ]
    }
   ],
   "source": [
    "# Una vez encontrados las variables categóricas y decidido el método de encodeamineto lo aplicamos\n",
    "df = pd.get_dummies(df, columns=[\"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\", \"contact\", \"month\", \"day_of_week\", \"poutcome\"], drop_first=True)  \n",
    "\n",
    "# Selección de las variables objetivo e independientes\n",
    "X = df.drop([\"y\"], axis=1)\n",
    "y = df[\"y\"]\n",
    "\n",
    "# Preprocesamos los datos mediante StandarScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Dividimos los datos en entrenamineto y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --------------------\n",
    "# MÉTODOS DE BALANCEO DE CLASES\n",
    "# --------------------\n",
    "# 1. Sobremuestreo aleatorio\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# 2. SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 3. Submuestreo aleatorio\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# 4. NearMiss (submuestreo basado en distancia)\n",
    "nearmiss = NearMiss()\n",
    "X_train_nm, y_train_nm = nearmiss.fit_resample(X_train, y_train)\n",
    "\n",
    "# --------------------\n",
    "# EVALUACIÓN DE MÉTODOS DE BALANCEO\n",
    "# --------------------\n",
    "resultados_balanceo = {}\n",
    "\n",
    "def evaluar_balanceo(X_train_resampled, y_train_resampled, metodo):\n",
    "    # Creación del modelo de RL\n",
    "    model = LogisticRegression(C=0.1, solver='liblinear', max_iter=500)\n",
    "    # Entreno el modelo con los datos de cada modelo\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    # Realizo predicciones con el modelo\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calculo la precisión del modelo sacando las métricas\n",
    "    f1 = f1_score(y_test, y_pred) * 100\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1]) * 100\n",
    "    resultados_balanceo[metodo] = (f1, auc)\n",
    "    # Imprimimos los resultados\n",
    "    print(f\"\\nResultados con {metodo}:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"F1-Score: {f1:.2f}%\")\n",
    "    print(f\"AUC-ROC: {auc:.2f}%\")\n",
    "\n",
    "evaluar_balanceo(X_train_ros, y_train_ros, \"Sobremuestreo Aleatorio\")\n",
    "evaluar_balanceo(X_train_smote, y_train_smote, \"SMOTE\")\n",
    "evaluar_balanceo(X_train_rus, y_train_rus, \"Submuestreo Aleatorio\")\n",
    "evaluar_balanceo(X_train_nm, y_train_nm, \"NearMiss\")\n",
    "\n",
    "# Seleccionar el mejor método de balanceo\n",
    "mejor_metodo = max(resultados_balanceo, key=lambda k: resultados_balanceo[k])\n",
    "print(f\"\\nEl mejor método de balanceo es: {mejor_metodo} con F1-Score: {resultados_balanceo[mejor_metodo][0]:.2f}% y AUC-ROC: {resultados_balanceo[mejor_metodo][1]:.2f}%\")\n",
    "\n",
    "# Obtener los datos balanceados del mejor método encontrado\n",
    "if mejor_metodo == \"Sobremuestreo Aleatorio\":\n",
    "    X_train_resampled, y_train_resampled = X_train_ros, y_train_ros\n",
    "elif mejor_metodo == \"SMOTE\":\n",
    "    X_train_resampled, y_train_resampled = X_train_smote, y_train_smote\n",
    "elif mejor_metodo == \"Submuestreo Aleatorio\":\n",
    "    X_train_resampled, y_train_resampled = X_train_rus, y_train_rus\n",
    "elif mejor_metodo == \"NearMiss\":\n",
    "    X_train_resampled, y_train_resampled = X_train_nm, y_train_nm\n",
    "\n",
    "# --------------------\n",
    "# MÉTODO 1: Ajuste manual de hiperparámetros\n",
    "# --------------------\n",
    "manual_model = LogisticRegression(C=0.1, solver='liblinear', max_iter=500)  # Ejemplo de hiperparámetros ajustados manualmente\n",
    "manual_model.fit(X_train_resampled, y_train_resampled)  # Entrenar modelo\n",
    "\n",
    "# Predicciones\n",
    "y_pred_manual = manual_model.predict(X_test)\n",
    "\n",
    "# Evaluación del modelo ajustado manualmente\n",
    "print(\"\\nResultados con ajuste manual de hiperparámetros:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, manual_model.predict_proba(X_test)[:,1]) * 100:.2f}%\")\n",
    "\n",
    "# --------------------\n",
    "# MÉTODO 2: Ajuste automático con GridSearchCV\n",
    "# --------------------\n",
    "parametros = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],  # Diferentes valores de regularización\n",
    "    \"solver\": [\"liblinear\", \"lbfgs\"]  # Diferentes algoritmos de optimización\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=500), parametros, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)  # Entrenar búsqueda de hiperparámetros\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicciones del mejor modelo\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluación del mejor modelo\n",
    "print(\"\\nResultados con ajuste automático de hiperparámetros:\")\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor Accuracy en validación cruzada: {grid_search.best_score_ * 100:.2f}%\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1]) * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# ENTRENAMIENTO FINAL Y EVALUACIÓN\n",
    "# --------------------\n",
    "\n",
    "# Entrenar el mejor modelo con los datos balanceados\n",
    "best_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Realizar predicciones finales con el mejor modelo y el mejor balanceo\n",
    "y_pred_final = best_model.predict(X_test)\n",
    "\n",
    "# Crear DataFrame de resultados\n",
    "resultados = pd.DataFrame({\n",
    "    \"Real\": y_test.values,\n",
    "    \"Predicción\": y_pred_final\n",
    "})\n",
    "\n",
    "# Mapear valores 0 y 1 a etiquetas comprensibles\n",
    "resultados[\"Real\"] = resultados[\"Real\"].map({0: \"No clase y\", 1: \"clase y\"})\n",
    "resultados[\"Predicción\"] = resultados[\"Predicción\"].map({0: \"No clase y\", 1: \"clase y\"})\n",
    "\n",
    "# Mostrar las primeras filas de la tabla\n",
    "print(resultados.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
